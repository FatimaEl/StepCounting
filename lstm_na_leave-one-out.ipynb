{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziyi/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lstm network for sighted people\n",
    "# leave-one-out & cross-validation\n",
    "# Network Parameters\n",
    "num_input = 6 # number of used sensor data\n",
    "timesteps = 100 # timesteps\n",
    "num_hidden = 100 # hidden layer num of features\n",
    "num_output= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read sensor data from csv files\n",
    "def read_sensor(filename):\n",
    "    with open(filename, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        #[17:20] rotationRateX, rotation-RateY, rotationRateZ, \n",
    "        #[20:23] userAccelerationX, userAc-celerationY, userAccelerationZ\n",
    "        dataset = [row[17:23] for row in reader]\n",
    "        return np.array(dataset)\n",
    "\n",
    "# read ground trurh data from xml files\n",
    "def read_xml(filename, length):\n",
    "    f = open(filename)\n",
    "    cts = f.read()\n",
    "    f.close()\n",
    "\n",
    "    p_foot = re.compile(r'<WhichFoot>(.*?)</WhichFoot>')\n",
    "    all_foot = p_foot.findall(cts)\n",
    "\n",
    "    p_time = re.compile(r'<Time>(.*?)</Time>')\n",
    "    all_time = p_time.findall(cts)\n",
    "\n",
    "    strike_times = []\n",
    "    #L-1 R-0\n",
    "    strike_times.append([0.0, 0.5])\n",
    "    for i in range(len(all_foot)):\n",
    "        if(all_foot[i]=='L'):\n",
    "            strike_times.append([float(all_time[i]), 1])\n",
    "        else:\n",
    "            strike_times.append([float(all_time[i]), 0])\n",
    "    strike_times[-1][1] = 0.5\n",
    "    strike_times.append([length/25.0, 0.5])\n",
    "\n",
    "    #transfer the ground truth data to binary signals\n",
    "    #left steps toggle the signal from 0 to 1 \n",
    "    #and right steps toggle the signal from 1 to 0\n",
    "    window_y = []\n",
    "    strike_index=0\n",
    "    for i in range(length):\n",
    "        if(i/25.0 >= strike_times[strike_index+1][0]):\n",
    "            strike_index += 1\n",
    "        window_y.append([strike_times[strike_index][1]])\n",
    "    \n",
    "    #change y to 0.5 in turn segments, which will be removed later\n",
    "    p_info = re.compile(r'<StartTime>(.*?)</StartTime>\\n\\t<EndTime>(.*?)</EndTime>\\n\\t<NSteps>(.*?)</NSteps>\\n\\t<Direction>(.*?)</Direction>')\n",
    "    all_info = p_info.findall(cts)#start_time, end_time, step_num, direction=turn\n",
    "\n",
    "    for i in range(len(all_info)):\n",
    "        if(all_info[i][3][:4]=='Turn'):\n",
    "            #print(all_info[i])\n",
    "            start_time = int(float(all_info[i][0])*25)\n",
    "            end_time = int(float(all_info[i][1])*25)\n",
    "            #print('start and end time : ', all_info[i][0], all_info[i][1])\n",
    "            for t in range(start_time-1, end_time):\n",
    "                window_y[t] = [0.5]\n",
    "                \n",
    "    #change y to 0.5 under feature label, which will be removed later\n",
    "    p_feature = re.compile(r'<Feature>\\n\\t\\t\\t<StartTime>(.*?)</StartTime>\\n\\t\\t\\t<EndTime>(.*?)</EndTime>')\n",
    "    all_feature = p_feature.findall(cts)#start_time, end_time, step_num, direction=turn\n",
    "    \n",
    "    #print(filename, length)\n",
    "    for i in range(len(all_feature)):\n",
    "        start_time = int(float(all_feature[i][0])*25)\n",
    "        end_time = int(float(all_feature[i][1])*25)\n",
    "        #print(start_time-1, end_time)\n",
    "        if(end_time<=length):\n",
    "            for t in range(start_time-1, end_time):\n",
    "                window_y[t] = [0.5]\n",
    "            \n",
    "    return window_y\n",
    "\n",
    "# add corresponding sensor data and label to training set\n",
    "def add_data(path, person, phone_location, assistant):\n",
    "    data_x = read_sensor('weallwalk/sensor/iPhoneSensors_T'+str(path)+'_ID'+str(person)+'_'+phone_location+'_'+assistant+'.csv')\n",
    "    data_y = read_xml('weallwalk/xml/T'+str(path)+'_ID'+str(person)+'_'+assistant+'.xml', len(data_x))\n",
    "    \n",
    "    #remove the sensor data in turn segment and feature labels which is marked as 0.5\n",
    "    split_x, split_x_part = [], []\n",
    "    split_y, split_y_part = [], []\n",
    "    for i in range(len(data_y)):\n",
    "        if(data_y[i][0]!=0.5):\n",
    "            split_y_part.append(data_y[i])\n",
    "            split_x_part.append(data_x[i])\n",
    "        else:\n",
    "            if(len(split_y_part)>0):\n",
    "                split_y.append(split_y_part)\n",
    "                split_x.append(split_x_part)\n",
    "                split_y_part = []\n",
    "                split_x_part = []\n",
    "    \n",
    "    #windowed the data (window size = timesteps)\n",
    "    data_x_seq, data_y_seq = [], []\n",
    "    for i in range(len(split_x)):\n",
    "        data_x_part, data_y_part = [], []\n",
    "        for j in range(len(split_x[i])-timesteps):\n",
    "            x = split_x[i][j:j+timesteps]\n",
    "            y = split_y[i][j:j+timesteps]\n",
    "            data_x_part.append(x)\n",
    "            data_y_part.append(y)\n",
    "        if(len(data_x_part)>0):\n",
    "            data_x_seq.append(data_x_part)\n",
    "            data_y_seq.append(data_y_part)\n",
    "    \n",
    "    return data_x_seq, data_y_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 11, '1L', 'NA'], [1, 12, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 12, '2R', 'NA'], [1, 13, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 12, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 12, '2R', 'NA'], [2, 13, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 12, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 12, '2R', 'NA'], [3, 13, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 12, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 12, '2R', 'NA'], [4, 13, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 12, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 12, '2R', 'NA'], [5, 13, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 12, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 12, '2R', 'NA'], [6, 13, '2R', 'NA'], [6, 14, '2R', 'NA']]\n"
     ]
    }
   ],
   "source": [
    "# training set (including validation)\n",
    "# participant id 11, 12, 13, 14\n",
    "all_train_data_list = []\n",
    "for i in range(1,7):\n",
    "    all_train_data_list.append([i, 11, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 12, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 13, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 14, '1L', 'NA'])\n",
    "#     step_data_list.append([i, 15, '1L', 'NA'])\n",
    "    all_train_data_list.append([i, 11, '2R', 'NA'])\n",
    "    all_train_data_list.append([i, 12, '2R', 'NA'])\n",
    "    all_train_data_list.append([i, 13, '2R', 'NA'])\n",
    "    all_train_data_list.append([i, 14, '2R', 'NA'])\n",
    "#     step_data_list.append([i, 15, '2R', 'NA'])    \n",
    "    \n",
    "print(all_train_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "[[1, 12, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 12, '2R', 'NA'], [1, 13, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 12, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 12, '2R', 'NA'], [2, 13, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 12, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 12, '2R', 'NA'], [3, 13, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 12, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 12, '2R', 'NA'], [4, 13, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 12, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 12, '2R', 'NA'], [5, 13, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 12, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 12, '2R', 'NA'], [6, 13, '2R', 'NA'], [6, 14, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 11, '1L', 'NA'], [1, 11, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 11, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 11, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 11, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 11, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 11, '2R', 'NA']]\n",
      "=====\n",
      "36\n",
      "[[1, 11, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 13, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 13, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 13, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 13, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 13, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 13, '2R', 'NA'], [6, 14, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 12, '1L', 'NA'], [1, 12, '2R', 'NA'], [2, 12, '1L', 'NA'], [2, 12, '2R', 'NA'], [3, 12, '1L', 'NA'], [3, 12, '2R', 'NA'], [4, 12, '1L', 'NA'], [4, 12, '2R', 'NA'], [5, 12, '1L', 'NA'], [5, 12, '2R', 'NA'], [6, 12, '1L', 'NA'], [6, 12, '2R', 'NA']]\n",
      "=====\n",
      "36\n",
      "[[1, 11, '1L', 'NA'], [1, 12, '1L', 'NA'], [1, 14, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 12, '2R', 'NA'], [1, 14, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 12, '1L', 'NA'], [2, 14, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 12, '2R', 'NA'], [2, 14, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 12, '1L', 'NA'], [3, 14, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 12, '2R', 'NA'], [3, 14, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 12, '1L', 'NA'], [4, 14, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 12, '2R', 'NA'], [4, 14, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 12, '1L', 'NA'], [5, 14, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 12, '2R', 'NA'], [5, 14, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 12, '1L', 'NA'], [6, 14, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 12, '2R', 'NA'], [6, 14, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 13, '1L', 'NA'], [1, 13, '2R', 'NA'], [2, 13, '1L', 'NA'], [2, 13, '2R', 'NA'], [3, 13, '1L', 'NA'], [3, 13, '2R', 'NA'], [4, 13, '1L', 'NA'], [4, 13, '2R', 'NA'], [5, 13, '1L', 'NA'], [5, 13, '2R', 'NA'], [6, 13, '1L', 'NA'], [6, 13, '2R', 'NA']]\n",
      "=====\n",
      "36\n",
      "[[1, 11, '1L', 'NA'], [1, 12, '1L', 'NA'], [1, 13, '1L', 'NA'], [1, 11, '2R', 'NA'], [1, 12, '2R', 'NA'], [1, 13, '2R', 'NA'], [2, 11, '1L', 'NA'], [2, 12, '1L', 'NA'], [2, 13, '1L', 'NA'], [2, 11, '2R', 'NA'], [2, 12, '2R', 'NA'], [2, 13, '2R', 'NA'], [3, 11, '1L', 'NA'], [3, 12, '1L', 'NA'], [3, 13, '1L', 'NA'], [3, 11, '2R', 'NA'], [3, 12, '2R', 'NA'], [3, 13, '2R', 'NA'], [4, 11, '1L', 'NA'], [4, 12, '1L', 'NA'], [4, 13, '1L', 'NA'], [4, 11, '2R', 'NA'], [4, 12, '2R', 'NA'], [4, 13, '2R', 'NA'], [5, 11, '1L', 'NA'], [5, 12, '1L', 'NA'], [5, 13, '1L', 'NA'], [5, 11, '2R', 'NA'], [5, 12, '2R', 'NA'], [5, 13, '2R', 'NA'], [6, 11, '1L', 'NA'], [6, 12, '1L', 'NA'], [6, 13, '1L', 'NA'], [6, 11, '2R', 'NA'], [6, 12, '2R', 'NA'], [6, 13, '2R', 'NA']]\n",
      "-----\n",
      "12\n",
      "[[1, 14, '1L', 'NA'], [1, 14, '2R', 'NA'], [2, 14, '1L', 'NA'], [2, 14, '2R', 'NA'], [3, 14, '1L', 'NA'], [3, 14, '2R', 'NA'], [4, 14, '1L', 'NA'], [4, 14, '2R', 'NA'], [5, 14, '1L', 'NA'], [5, 14, '2R', 'NA'], [6, 14, '1L', 'NA'], [6, 14, '2R', 'NA']]\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "#spliting training data and validation data\n",
    "step_train_data_list = []\n",
    "step_valid_data_list = []\n",
    "for i in range(11, 15):\n",
    "    step_train_data_list_part = [j for j in all_train_data_list if j[1]!=i]\n",
    "    step_valid_data_list_part = [j for j in all_train_data_list if j[1]==i]\n",
    "    print(len(step_train_data_list_part))\n",
    "    print(step_train_data_list_part)\n",
    "    print('-----')\n",
    "    print(len(step_valid_data_list_part))\n",
    "    print(step_valid_data_list_part)\n",
    "    print('=====')\n",
    "    step_train_data_list.append(step_train_data_list_part)\n",
    "    step_valid_data_list.append(step_valid_data_list_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "66949\n",
      "66949\n",
      "70644\n",
      "70644\n",
      "66239\n",
      "66239\n",
      "61833\n",
      "61833\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "# add data to training set\n",
    "train_x_list, train_y_list = [], []\n",
    "print(batch_size)\n",
    "\n",
    "for step_train_data in step_train_data_list:\n",
    "    data_x, data_y = [], []\n",
    "    \n",
    "    for i in step_train_data:\n",
    "        data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "        for dx in data_x_segement:\n",
    "            data_x.extend(dx)\n",
    "        for dy in data_y_segement:\n",
    "            data_y.extend(dy)\n",
    "    \n",
    "    print(len(data_x))\n",
    "#     print(len(data_y))\n",
    "    \n",
    "    order = list(range(0,len(data_x),1))\n",
    "    random.shuffle(order)\n",
    "\n",
    "    train_x = [data_x[i] for i in order]\n",
    "#     train_x.extend([train_x[i] for i in range(0, batch_size)])\n",
    "    train_y = [data_y[i] for i in order]\n",
    "#     train_y.extend([train_y[i] for i in range(0, batch_size)])\n",
    "\n",
    "    print(len(train_x))\n",
    "    \n",
    "    train_x_list.append(train_x)\n",
    "    train_y_list.append(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "47\n",
      "56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# add data to validation set\n",
    "valid_x_list, valid_y_list = [], []\n",
    "\n",
    "for step_valid_data in step_valid_data_list:\n",
    "    valid_x, valid_y=[], []\n",
    "    for i in step_valid_data:\n",
    "        data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "        valid_x.extend(data_x_segement)\n",
    "        valid_y.extend(data_y_segement)\n",
    "    \n",
    "    print(len(valid_x))\n",
    "#     print(len(valid_y))\n",
    "    \n",
    "    valid_x_list.append(valid_x)\n",
    "    valid_y_list.append(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 15, '1L', 'NA'], [1, 15, '2R', 'NA'], [2, 15, '1L', 'NA'], [2, 15, '2R', 'NA'], [3, 15, '1L', 'NA'], [3, 15, '2R', 'NA'], [4, 15, '1L', 'NA'], [4, 15, '2R', 'NA'], [5, 15, '1L', 'NA'], [5, 15, '2R', 'NA'], [6, 15, '1L', 'NA'], [6, 15, '2R', 'NA']]\n"
     ]
    }
   ],
   "source": [
    "# testing set\n",
    "# participant id 15\n",
    "step_test_list = []\n",
    "for i in range(1,7):\n",
    "    step_test_list.append([i, 15, '1L', 'NA'])\n",
    "    step_test_list.append([i, 15, '2R', 'NA'])    \n",
    "        \n",
    "print(step_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "54\n",
      "[30, 66, 725, 25, 30, 66, 725, 25, 63, 1037, 57, 8, 63, 1037, 57, 8, 1085, 220, 1085, 220, 148, 1024, 37, 971, 72, 787, 54, 707, 148, 1024, 37, 971, 72, 787, 54, 707, 289, 577, 87, 343, 231, 1049, 289, 577, 87, 343, 231, 1049, 554, 1091, 724, 554, 1091, 724]\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y=[], []\n",
    "for i in step_test_list:\n",
    "    data_x_segement, data_y_segement = add_data(i[0], i[1], i[2], i[3])\n",
    "    test_x.extend(data_x_segement)\n",
    "    test_y.extend(data_y_segement)\n",
    "    \n",
    "print(len(test_x))\n",
    "print(len(test_y))\n",
    "\n",
    "print([len(i) for i in test_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 100, 1)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS=2\n",
    "\n",
    "def LstmCell():\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_hidden)#, forget_bias=1.0)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=0.5)\n",
    "    return cell\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default(), tf.device('/gpu:0'):\n",
    "    # tf Graph input\n",
    "    X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "    Y = tf.placeholder(\"float\", [None, timesteps, num_output])\n",
    "    \n",
    "    # Define weights\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([num_hidden, num_output]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([num_output]))\n",
    "    }\n",
    "    \n",
    "    def RNN(x, weights, biases):\n",
    "        x = tf.unstack(x, timesteps, 1)\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([LstmCell() for _ in range(NUM_LAYERS)])\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "        outputs = tf.transpose(outputs, [1,0,2])\n",
    "\n",
    "#         return tf.matmul(outputs[-2], weights['out']) + biases['out']\n",
    "        ret = []\n",
    "#         print(outputs.shape)\n",
    "        for i in range(0, timesteps):\n",
    "            ret.append(tf.matmul(outputs[i], weights['out']) + biases['out'])\n",
    "            \n",
    "        return ret\n",
    "    \n",
    "    logits = RNN(X, weights, biases)\n",
    "    logits = tf.transpose(logits, [1,0,2])\n",
    "#     print(len(logits))\n",
    "    print(logits.shape)\n",
    "    print(logits[0].shape)\n",
    "    mean_train = tf.reduce_mean(X)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss)\n",
    "    \n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the accuarcy between real y and prediction _y\n",
    "def cal_accuarcy(y, _y):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in range(len(y[0])):\n",
    "        total += 1\n",
    "        if(y[0][i][0] == round(_y[0][i][0])):\n",
    "            count += 1\n",
    "    for i in range(1, len(y)):\n",
    "        total += 1\n",
    "        if(y[i][-1][0] == round(_y[i][-1][0])):\n",
    "            count += 1;\n",
    "    return(count*1.0/total)\n",
    "#     print(\"train accuarcy : \", count/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation  0\n",
      "Initialized\n",
      "Loss at step 0: 1.307528, train accuarcy : 0.352113\n",
      "Loss at step 200: 0.119049, train accuarcy : 0.526761\n",
      "Loss at step 400: 0.099955, train accuarcy : 0.591549\n",
      "Loss at step 600: 0.086865, train accuarcy : 0.560563\n",
      "Loss at step 800: 0.083721, train accuarcy : 0.577465\n",
      "Loss at step 1000: 0.070504, train accuarcy : 0.402817\n",
      "Loss at step 1200: 0.065027, train accuarcy : 0.571831\n",
      "Loss at step 1400: 0.065760, train accuarcy : 0.628169\n",
      "Loss at step 1600: 0.062293, train accuarcy : 0.397183\n",
      "Loss at step 1800: 0.056003, train accuarcy : 0.422535\n",
      "Loss at step 2000: 0.059960, train accuarcy : 0.416901\n",
      "cross validation  1\n",
      "Initialized\n",
      "Loss at step 0: 1.538159, train accuarcy : 0.183099\n",
      "Loss at step 200: 0.127567, train accuarcy : 0.630986\n",
      "Loss at step 400: 0.105386, train accuarcy : 0.569014\n",
      "Loss at step 600: 0.092791, train accuarcy : 0.521127\n",
      "Loss at step 800: 0.083204, train accuarcy : 0.602817\n",
      "Loss at step 1000: 0.079383, train accuarcy : 0.614085\n",
      "Loss at step 1200: 0.072643, train accuarcy : 0.383099\n",
      "Loss at step 1400: 0.068213, train accuarcy : 0.394366\n",
      "Loss at step 1600: 0.064987, train accuarcy : 0.518310\n",
      "Loss at step 1800: 0.062833, train accuarcy : 0.394366\n",
      "Loss at step 2000: 0.059012, train accuarcy : 0.414085\n",
      "cross validation  2\n",
      "Initialized\n",
      "Loss at step 0: 2.323352, train accuarcy : 0.109859\n",
      "Loss at step 200: 0.147226, train accuarcy : 0.526761\n",
      "Loss at step 400: 0.122357, train accuarcy : 0.456338\n",
      "Loss at step 600: 0.108722, train accuarcy : 0.470423\n",
      "Loss at step 800: 0.103347, train accuarcy : 0.515493\n",
      "Loss at step 1000: 0.092357, train accuarcy : 0.523944\n",
      "Loss at step 1200: 0.090778, train accuarcy : 0.450704\n",
      "Loss at step 1400: 0.081871, train accuarcy : 0.569014\n",
      "Loss at step 1600: 0.078303, train accuarcy : 0.445070\n",
      "Loss at step 1800: 0.075223, train accuarcy : 0.625352\n",
      "Loss at step 2000: 0.071993, train accuarcy : 0.602817\n",
      "cross validation  3\n",
      "Initialized\n",
      "Loss at step 0: 1.237153, train accuarcy : 0.259155\n",
      "Loss at step 200: 0.112751, train accuarcy : 0.560563\n",
      "Loss at step 400: 0.094856, train accuarcy : 0.521127\n",
      "Loss at step 600: 0.079428, train accuarcy : 0.447887\n",
      "Loss at step 800: 0.073787, train accuarcy : 0.487324\n",
      "Loss at step 1000: 0.065596, train accuarcy : 0.538028\n",
      "Loss at step 1200: 0.065295, train accuarcy : 0.492958\n",
      "Loss at step 1400: 0.058660, train accuarcy : 0.614085\n",
      "Loss at step 1600: 0.058118, train accuarcy : 0.436620\n",
      "Loss at step 1800: 0.053809, train accuarcy : 0.605634\n",
      "Loss at step 2000: 0.052494, train accuarcy : 0.405634\n"
     ]
    }
   ],
   "source": [
    "training_steps = 2001\n",
    "valid_loss_list, valid_logits_list = [], []\n",
    "test_loss_list, test_logits_list = [], []\n",
    "batch_start = 0\n",
    "\n",
    "for i in range(0,len(valid_x_list)):\n",
    "    batch_start=0\n",
    "    print(\"cross validation \", i)\n",
    "    train_x = train_x_list[i]\n",
    "    train_y = train_y_list[i]\n",
    "    train_length = len(train_x_list[i])-256\n",
    "    valid_x = valid_x_list[i]\n",
    "    valid_y = valid_y_list[i]\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Session(graph=graph, config=config) as session:\n",
    "#         saver.restore(session, tf.train.latest_checkpoint('lstm_check'))\n",
    "#         saver.restore(session, \"lstm_check/my-model-gpu-error-metric-dropout2-wc-10fold-2.ckpt-00\")\n",
    "        tf.global_variables_initializer().run()\n",
    "        print('Initialized')\n",
    "        for step in range(training_steps):\n",
    "            if(batch_start+batch_size>len(train_x)):\n",
    "                print(\"epoch+1\")\n",
    "                order = list(range(0,len(train_x),1))\n",
    "                random.shuffle(order)\n",
    "                train_x = [train_x[i] for i in order]\n",
    "                train_y = [train_y[i] for i in order]\n",
    "                batch_start=0\n",
    "            feed_dict = {X: train_x[batch_start:batch_start+batch_size], Y: train_y[batch_start:batch_start+batch_size]}\n",
    "            _, l, predictions, m = session.run([optimizer, loss, logits, mean_train], feed_dict = feed_dict)\n",
    "            batch_start += batch_size\n",
    "            if (step % 200 == 0):\n",
    "                train_accuarcy = cal_accuarcy(train_y[batch_start:batch_start+batch_size], predictions)\n",
    "                print('Loss at step %d: %f, train accuarcy : %f' % (step, l, train_accuarcy))\n",
    "                #train accuarcy\n",
    "            if (step % 500 == 0):\n",
    "                saver.save(session, 'lstm_check/my-model-gpu-error-metric-dropout2-wc-10fold-'+str(i+1)+'.ckpt', global_step=step)\n",
    "            batch_start += batch_size\n",
    "            if(batch_start>=train_length):\n",
    "                batch_start -=train_length\n",
    "        valid_loss, valid_logits = [], []\n",
    "        for j in range(len(valid_x)):\n",
    "            valid_loss_part, valid_logits_part = session.run([loss,logits], feed_dict={X: valid_x[j], Y: valid_y[j]})\n",
    "            valid_loss.append(valid_loss_part)\n",
    "            valid_logits.append(valid_logits_part)\n",
    "\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_logits_list.append(valid_logits)\n",
    "\n",
    "        test_loss, test_logits = [], []\n",
    "        for j in range(len(test_x)):\n",
    "            test_loss_part, test_logits_part = session.run([loss,logits], feed_dict={X: test_x[j], Y: test_y[j]})\n",
    "            test_loss.append(test_loss_part)\n",
    "            test_logits.append(test_logits_part)\n",
    "\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_logits_list.append(test_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Error Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17887\n",
      "26754\n",
      "valid accuarcy :  0.6685729236749645\n",
      "Step number for each segement\n",
      "[10, 58, 8, 10, 58, 8, 8, 84, 12, 7, 8, 84, 12, 7, 79, 22, 79, 22, 20, 80, 10, 79, 11, 60, 10, 54, 20, 80, 10, 79, 11, 60, 10, 54, 26, 44, 20, 27, 21, 82, 26, 44, 20, 27, 21, 82, 30, 77, 6, 30, 77, 6]\n",
      "[12, 66, 8, 11, 58, 9, 13, 120, 17, 8, 11, 86, 12, 7, 86, 26, 80, 25, 23, 99, 16, 96, 12, 79, 12, 76, 22, 80, 12, 81, 12, 59, 11, 55, 29, 57, 23, 32, 30, 107, 28, 44, 23, 28, 22, 91, 39, 103, 5, 30, 80, 8]\n",
      "52\n",
      "52\n",
      "407\n",
      "[2, 14, 2, 1, 0, 1, 5, 47, 6, 1, 0, 9, 1, 1, 7, 6, 11, 7, 3, 23, 6, 16, 3, 30, 2, 30, 1, 5, 1, 7, 0, 1, 3, 7, 9, 19, 3, 8, 10, 34, 0, 3, 0, 0, 0, 8, 14, 36, 0, 0, 2, 2]\n",
      "52\n",
      "291\n",
      "[2, 8, 0, 1, 0, 1, 5, 36, 5, 1, 3, 2, 0, 0, 7, 4, 1, 3, 3, 19, 6, 17, 1, 19, 2, 22, 2, 0, 2, 2, 1, 0, 1, 1, 3, 13, 3, 5, 9, 25, 2, 0, 3, 1, 1, 9, 9, 26, 0, 0, 3, 2]\n",
      "error : \n",
      "total undercount metric 1:\t 0.09682539682539683\n",
      "total overcount metric 1:\t 0.24973544973544973\n",
      "total undercount metric 2:\t 0.08042328042328042\n",
      "total overcount metric 2:\t 0.23333333333333334\n",
      "total undercount metric 3:\t 0.0010582010582010583\n",
      "total overcount metric 3:\t 0.15396825396825398\n",
      "==============================================================\n",
      "13511\n",
      "22564\n",
      "valid accuarcy :  0.5987856762985286\n",
      "Step number for each segement\n",
      "[9, 49, 9, 49, 7, 69, 8, 6, 7, 69, 8, 6, 73, 19, 73, 19, 18, 72, 9, 70, 9, 52, 9, 18, 72, 9, 70, 9, 52, 9, 48, 23, 39, 18, 24, 19, 73, 23, 39, 18, 24, 19, 73, 34, 67, 34, 67]\n",
      "[8, 61, 8, 17, 13, 98, 9, 8, 8, 49, 10, 8, 109, 25, 40, 19, 29, 97, 19, 76, 13, 76, 15, 12, 31, 11, 36, 7, 31, 9, 47, 35, 46, 24, 34, 31, 114, 20, 27, 17, 23, 11, 57, 54, 93, 28, 43]\n",
      "47\n",
      "47\n",
      "606\n",
      "[3, 14, 3, 8, 4, 35, 3, 3, 4, 20, 4, 0, 37, 11, 17, 8, 13, 29, 10, 12, 3, 28, 7, 5, 11, 4, 16, 2, 13, 4, 23, 17, 18, 8, 10, 12, 42, 7, 7, 7, 10, 2, 22, 25, 38, 13, 14]\n",
      "47\n",
      "319\n",
      "[0, 12, 0, 0, 6, 29, 1, 2, 1, 0, 2, 2, 36, 6, 0, 0, 11, 25, 10, 6, 4, 24, 6, 0, 0, 2, 0, 0, 0, 0, 0, 12, 7, 6, 10, 12, 41, 0, 0, 0, 0, 0, 0, 20, 26, 0, 0]\n",
      "error : \n",
      "total undercount metric 1:\t 0.371875\n",
      "total overcount metric 1:\t 0.406875\n",
      "total undercount metric 2:\t 0.243125\n",
      "total overcount metric 2:\t 0.278125\n",
      "total undercount metric 3:\t 0.164375\n",
      "total overcount metric 3:\t 0.199375\n",
      "==============================================================\n",
      "20942\n",
      "27860\n",
      "valid accuarcy :  0.7516870064608758\n",
      "Step number for each segement\n",
      "[8, 10, 58, 8, 10, 58, 81, 12, 7, 81, 12, 7, 83, 23, 83, 23, 17, 78, 10, 76, 10, 56, 9, 55, 17, 78, 10, 76, 10, 56, 9, 55, 25, 19, 19, 19, 26, 20, 76, 25, 19, 19, 19, 26, 20, 76, 15, 15, 7, 46, 49, 15, 15, 7, 46, 49]\n",
      "[15, 18, 82, 8, 13, 60, 118, 18, 12, 86, 17, 12, 126, 41, 89, 26, 19, 110, 16, 104, 13, 94, 14, 87, 21, 81, 10, 85, 11, 58, 12, 65, 41, 36, 32, 24, 38, 26, 114, 28, 21, 25, 22, 31, 33, 113, 17, 24, 12, 72, 63, 17, 22, 10, 53, 74]\n",
      "56\n",
      "56\n",
      "795\n",
      "[5, 6, 31, 0, 3, 6, 47, 4, 4, 10, 6, 4, 51, 18, 10, 6, 7, 46, 7, 42, 3, 39, 5, 38, 3, 9, 3, 10, 1, 5, 1, 11, 19, 16, 15, 8, 13, 7, 52, 5, 4, 6, 4, 6, 16, 45, 9, 11, 4, 32, 30, 3, 9, 3, 9, 28]\n",
      "56\n",
      "631\n",
      "[7, 8, 24, 0, 3, 2, 37, 6, 5, 5, 5, 5, 43, 18, 6, 3, 2, 32, 6, 28, 3, 38, 5, 32, 4, 3, 0, 9, 1, 2, 3, 10, 16, 17, 13, 5, 12, 6, 38, 3, 2, 6, 3, 5, 13, 37, 2, 9, 5, 26, 14, 2, 7, 3, 7, 25]\n",
      "error : \n",
      "total undercount metric 1:\t 0.13455328310010764\n",
      "total overcount metric 1:\t 0.47416576964477936\n",
      "total undercount metric 2:\t 0.04628632938643703\n",
      "total overcount metric 2:\t 0.3858988159311087\n",
      "total undercount metric 3:\t 0.0\n",
      "total overcount metric 3:\t 0.3396124865446717\n",
      "==============================================================\n",
      "17443\n",
      "32266\n",
      "valid accuarcy :  0.5406000123969503\n",
      "Step number for each segement\n",
      "[9, 11, 66, 7, 9, 11, 66, 7, 9, 93, 11, 8, 9, 93, 11, 8, 93, 25, 93, 25, 19, 93, 12, 77, 13, 67, 11, 62, 19, 93, 12, 77, 13, 67, 11, 62, 7, 27, 48, 23, 34, 25, 50, 7, 27, 48, 23, 34, 25, 50, 44, 86, 60, 44, 86, 60]\n",
      "[10, 11, 66, 7, 9, 11, 66, 9, 10, 93, 11, 9, 8, 93, 12, 8, 94, 25, 93, 26, 19, 93, 12, 76, 13, 67, 11, 63, 19, 93, 12, 77, 13, 68, 11, 64, 8, 27, 48, 22, 34, 25, 49, 8, 27, 49, 22, 35, 27, 49, 44, 85, 60, 44, 85, 61]\n",
      "56\n",
      "56\n",
      "651\n",
      "[3, 4, 7, 0, 3, 5, 25, 3, 2, 15, 1, 3, 3, 42, 6, 3, 4, 3, 44, 13, 8, 41, 6, 36, 4, 32, 5, 29, 8, 44, 6, 37, 5, 11, 1, 0, 2, 9, 20, 4, 11, 6, 21, 1, 1, 2, 2, 1, 2, 2, 2, 6, 7, 22, 40, 28]\n",
      "56\n",
      "19\n",
      "[1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1]\n",
      "error : \n",
      "total undercount metric 1:\t 0.31055045871559633\n",
      "total overcount metric 1:\t 0.3155963302752294\n",
      "total undercount metric 2:\t 0.020642201834862386\n",
      "total overcount metric 2:\t 0.025688073394495414\n",
      "total undercount metric 3:\t 0.003669724770642202\n",
      "total overcount metric 3:\t 0.00871559633027523\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "m1u, m1o, m2u, m2o, m3u, m3o = [], [], [], [], [], []\n",
    "    \n",
    "for k in range(len(valid_logits_list)):\n",
    "    \n",
    "    valid_logits = valid_logits_list[k]\n",
    "    valid_y = valid_y_list[k]    \n",
    "    \n",
    "    valid_y_seq_list, valid_logits_bin_list = [], []\n",
    "\n",
    "    for t in valid_logits:  \n",
    "        t_all = [i for i in t[0]]\n",
    "        t_all.extend([i[-1] for i in t[1:]])\n",
    "    #     print(len(t_all)-len(t))\n",
    "\n",
    "        valid_logits_part = [[round(i[0])] for i in t_all]\n",
    "        for i in range(1, len(valid_logits_part)-1):\n",
    "            if(valid_logits_part[i-1][0]!=valid_logits_part[i][0] and valid_logits_part[i-1][0]==valid_logits_part[i+1][0]):\n",
    "                valid_logits_part[i][0]=valid_logits_part[i-1][0]  \n",
    "\n",
    "        valid_logits_bin_list.append(valid_logits_part)\n",
    "\n",
    "    for t in valid_y:  \n",
    "        t_all = [i for i in t[0]]\n",
    "        t_all.extend([i[-1] for i in t[1:]])\n",
    "        valid_y_seq_list.append(t_all)\n",
    "\n",
    "    # print(valid_y_seq_list)\n",
    "\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in range(0, len(valid_y_seq_list)):\n",
    "        total += len(valid_y_seq_list[i])\n",
    "    #     print(len(valid_y_seq_list[i]), len(valid_logits_bin_list[i]))\n",
    "\n",
    "        for j in range(0, len(valid_y_seq_list[i])):\n",
    "            if(valid_y_seq_list[i][j][0] == valid_logits_bin_list[i][j][0]):\n",
    "                count += 1\n",
    "\n",
    "    print(count)\n",
    "    print(total)\n",
    "    print(\"valid accuarcy : \", count*1.0/total)\n",
    "    \n",
    "    #===========================================\n",
    "    step_time_actual, step_time_predict= [], []\n",
    "    step_time_actual_gap = []\n",
    "\n",
    "    #valid_y_seq_list, valid_logits_bin_list\n",
    "    for i in range(0, len(valid_y_seq_list)):\n",
    "        step_time_actual_part, step_time_predict_part= [], []\n",
    "        for j in range(1, len(valid_y_seq_list[i])):\n",
    "            if(abs(valid_y_seq_list[i][j][0]-valid_y_seq_list[i][j-1][0])>0.5):\n",
    "                step_time_actual_part.append(j)\n",
    "        #     if(abs(valid_logits[i][0]-valid_logits[i-1][0])>0.5):\n",
    "            if(abs(valid_logits_bin_list[i][j][0]-valid_logits_bin_list[i][j-1][0])>0.5):\n",
    "                step_time_predict_part.append(j)\n",
    "        step_time_actual.append(step_time_actual_part)\n",
    "        step_time_predict.append(step_time_predict_part)\n",
    "\n",
    "        step_time_actual_gap_part = []\n",
    "        step_time_actual_gap_part.append(0)\n",
    "    #     step_time_actual_gap_part.append(step_time_actual_part[0]/2.0)\n",
    "        for i in range(1, len(step_time_actual_part)):\n",
    "            step_time_actual_gap_part.append((step_time_actual_part[i-1]+step_time_actual_part[i])/2.0)\n",
    "        step_time_actual_gap_part.append(step_time_actual_part[-1]*2)\n",
    "        step_time_actual_gap.append(step_time_actual_gap_part)\n",
    "\n",
    "    print('Step number for each segement')\n",
    "    print([len(i) for i in step_time_actual])   \n",
    "    print([len(i) for i in step_time_predict])\n",
    "    \n",
    "    #===================================================\n",
    "    total_step_count = sum([len(i) for i in step_time_actual])\n",
    "    metric1_undercount = 0\n",
    "    metric2_undercount = 0\n",
    "    metric3_undercount = 0\n",
    "    metric1_overcount = 0\n",
    "    metric2_overcount = 0\n",
    "    metric3_overcount = 0\n",
    "    \n",
    "    metric1_overcount_list = []\n",
    "    metric2_overcount_list = []\n",
    "    metric3_overcount_list = []\n",
    "\n",
    "    print(len(valid_y))\n",
    "\n",
    "    for i in range(len(valid_y)):\n",
    "        step_count = len(step_time_actual[i])\n",
    "        undercount = 0\n",
    "        overcount = 0\n",
    "        \n",
    "        metric1_overcount += len([t for t in step_time_predict[i] if t<step_time_actual[i][0]])\n",
    "        for j in range(1, step_count):\n",
    "            gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][j-1] and t<step_time_actual[i][j]]\n",
    "        #     print(gap_count)\n",
    "            if(len(gap_count)>1):\n",
    "                overcount += len(gap_count)-1\n",
    "            if(len(gap_count)<1):\n",
    "                undercount += 1\n",
    "        gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][-1]]\n",
    "        if(len(gap_count)>1):\n",
    "            overcount += len(gap_count)-1\n",
    "        if(len(gap_count)<1):\n",
    "            undercount += 1\n",
    "\n",
    "        metric1_undercount += undercount\n",
    "        metric1_overcount += overcount\n",
    "        metric1_overcount_list.append(overcount)\n",
    "\n",
    "        undercount = 0\n",
    "        overcount = 0\n",
    "        for j in range(1, len(step_time_actual_gap[i])):\n",
    "            gap_count = [t for t in step_time_predict[i] if t>=step_time_actual_gap[i][j-1] and t<step_time_actual_gap[i][j]]\n",
    "        #     print(gap_count)\n",
    "            if(len(gap_count)>1):\n",
    "                overcount += (len(gap_count)-1)\n",
    "            if(len(gap_count)<1):\n",
    "                undercount += 1    \n",
    "\n",
    "        metric2_undercount += undercount\n",
    "        metric2_overcount += overcount  \n",
    "        metric2_overcount_list.append(overcount)\n",
    "\n",
    "        diff = len(step_time_predict[i])-len(step_time_actual[i])\n",
    "#         print(step_time_actual[i])\n",
    "#         print(step_time_predict[i])\n",
    "#         print('------')\n",
    "\n",
    "        if(diff<0):\n",
    "    #         print('segement undercount : ', 1-len(step_time_predict[i])*1.0/len(step_time_actual[i]))\n",
    "            metric3_undercount -= diff\n",
    "            metric3_overcount_list.append(0)\n",
    "    #     if(diff>=0):\n",
    "        else:\n",
    "    #         print('segement overcount : ', 1-len(step_time_actual[i])*1.0/len(step_time_predict[i]))\n",
    "            metric3_overcount += diff\n",
    "            metric3_overcount_list.append(diff)\n",
    "\n",
    "    print(len(metric1_overcount_list))\n",
    "    print(sum(metric1_overcount_list))\n",
    "    print(metric1_overcount_list)\n",
    "    print(len(metric3_overcount_list))\n",
    "    print(sum(metric3_overcount_list))\n",
    "    print(metric3_overcount_list)\n",
    "\n",
    "    print('error : ')\n",
    "    print(\"total undercount metric 1:\\t\", metric1_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 1:\\t\", metric1_overcount*1.0/total_step_count)\n",
    "    print(\"total undercount metric 2:\\t\", metric2_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 2:\\t\", metric2_overcount*1.0/total_step_count)\n",
    "    print(\"total undercount metric 3:\\t\", metric3_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 3:\\t\", metric3_overcount*1.0/total_step_count)\n",
    "    \n",
    "    m1u.append(metric1_undercount*1.0/total_step_count)\n",
    "    m1o.append(metric1_overcount*1.0/total_step_count)\n",
    "    m2u.append(metric2_undercount*1.0/total_step_count)\n",
    "    m2o.append(metric2_overcount*1.0/total_step_count)\n",
    "    m3u.append(metric3_undercount*1.0/total_step_count)\n",
    "    m3o.append(metric3_overcount*1.0/total_step_count)\n",
    "    \n",
    "    print(\"==============================================================\")\n",
    "\n",
    "# filename = 'tmp/na_valid_timesteps='+str(timesteps)+'_trainingsteps='+str(training_steps)+'lr='+str(0.1)+'1.csv'\n",
    "# with open(filename,\"w\") as csvfile: \n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerow([\"cv0\",\"cv1\",\"cv2\",\"cv3\"])\n",
    "#     writer.writerows([m1u, m1o, m2u, m2o, m3u, m3o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12722\n",
      "29468\n",
      "test accuarcy :  0.431722546491109\n",
      "Step number for each segement\n",
      "[8, 10, 57, 7, 8, 10, 57, 7, 9, 80, 11, 6, 9, 80, 11, 6, 84, 22, 84, 22, 17, 82, 10, 80, 12, 63, 11, 57, 17, 82, 10, 80, 12, 63, 11, 57, 27, 46, 13, 31, 22, 82, 27, 46, 13, 31, 22, 82, 43, 82, 58, 43, 82, 58]\n",
      "[12, 12, 59, 12, 9, 14, 56, 12, 11, 94, 13, 10, 13, 55, 11, 8, 88, 22, 73, 20, 19, 86, 10, 81, 12, 64, 12, 57, 16, 67, 16, 39, 12, 66, 7, 72, 29, 46, 12, 30, 25, 88, 30, 52, 12, 34, 13, 52, 48, 94, 60, 57, 93, 62]\n",
      "54\n",
      "54\n",
      "625\n",
      "[4, 5, 5, 4, 4, 7, 27, 5, 3, 21, 3, 3, 5, 27, 5, 3, 18, 2, 35, 9, 3, 10, 4, 6, 1, 8, 2, 2, 7, 32, 8, 17, 5, 34, 3, 32, 3, 3, 1, 1, 2, 15, 13, 23, 6, 12, 5, 24, 16, 23, 7, 27, 44, 31]\n",
      "54\n",
      "159\n",
      "[4, 2, 2, 5, 1, 4, 0, 5, 2, 14, 2, 4, 4, 0, 0, 2, 4, 0, 0, 0, 2, 4, 0, 1, 0, 1, 1, 0, 0, 0, 6, 0, 0, 3, 0, 15, 2, 0, 0, 0, 3, 6, 3, 6, 0, 3, 0, 0, 5, 12, 2, 14, 11, 4]\n",
      "error : \n",
      "total undercount metric 1:\t 0.31407766990291264\n",
      "total overcount metric 1:\t 0.32233009708737864\n",
      "total undercount metric 2:\t 0.17718446601941748\n",
      "total overcount metric 2:\t 0.18543689320388348\n",
      "total undercount metric 3:\t 0.06893203883495146\n",
      "total overcount metric 3:\t 0.07718446601941747\n",
      "==============================================================\n",
      "10714\n",
      "29468\n",
      "test accuarcy :  0.36358083344645037\n",
      "Step number for each segement\n",
      "[8, 10, 57, 7, 8, 10, 57, 7, 9, 80, 11, 6, 9, 80, 11, 6, 84, 22, 84, 22, 17, 82, 10, 80, 12, 63, 11, 57, 17, 82, 10, 80, 12, 63, 11, 57, 27, 46, 13, 31, 22, 82, 27, 46, 13, 31, 22, 82, 43, 82, 58, 43, 82, 58]\n",
      "[8, 12, 63, 9, 15, 20, 82, 14, 9, 100, 11, 7, 19, 96, 17, 12, 89, 24, 111, 29, 20, 88, 13, 79, 12, 63, 10, 59, 26, 100, 16, 91, 17, 90, 16, 91, 34, 46, 14, 30, 24, 85, 52, 87, 23, 58, 39, 106, 45, 84, 58, 85, 133, 95]\n",
      "54\n",
      "54\n",
      "810\n",
      "[0, 2, 6, 2, 7, 10, 41, 7, 0, 20, 2, 1, 8, 48, 8, 6, 5, 2, 29, 7, 6, 15, 3, 0, 5, 0, 1, 5, 11, 49, 8, 41, 8, 45, 8, 44, 8, 1, 2, 3, 1, 4, 24, 43, 11, 29, 19, 50, 3, 4, 1, 42, 63, 42]\n",
      "54\n",
      "579\n",
      "[0, 2, 6, 2, 7, 10, 25, 7, 0, 20, 0, 1, 10, 16, 6, 6, 5, 2, 27, 7, 3, 6, 3, 0, 0, 0, 0, 2, 9, 18, 6, 11, 5, 27, 5, 34, 7, 0, 1, 0, 2, 3, 25, 41, 10, 27, 17, 24, 2, 2, 0, 42, 51, 37]\n",
      "error : \n",
      "total undercount metric 1:\t 0.12864077669902912\n",
      "total overcount metric 1:\t 0.408252427184466\n",
      "total undercount metric 2:\t 0.08932038834951456\n",
      "total overcount metric 2:\t 0.36893203883495146\n",
      "total undercount metric 3:\t 0.0014563106796116505\n",
      "total overcount metric 3:\t 0.28106796116504856\n",
      "==============================================================\n",
      "13359\n",
      "29468\n",
      "test accuarcy :  0.45333921542011674\n",
      "Step number for each segement\n",
      "[8, 10, 57, 7, 8, 10, 57, 7, 9, 80, 11, 6, 9, 80, 11, 6, 84, 22, 84, 22, 17, 82, 10, 80, 12, 63, 11, 57, 17, 82, 10, 80, 12, 63, 11, 57, 27, 46, 13, 31, 22, 82, 27, 46, 13, 31, 22, 82, 43, 82, 58, 43, 82, 58]\n",
      "[17, 13, 85, 10, 2, 2, 8, 1, 15, 117, 20, 17, 3, 1, 2, 1, 147, 27, 4, 0, 19, 120, 17, 93, 24, 74, 15, 81, 3, 1, 2, 5, 2, 4, 1, 2, 51, 76, 22, 51, 43, 135, 3, 5, 2, 11, 1, 0, 75, 142, 76, 8, 7, 8]\n",
      "54\n",
      "54\n",
      "727\n",
      "[6, 1, 26, 3, 0, 1, 4, 0, 6, 34, 10, 8, 1, 0, 1, 0, 63, 13, 1, 0, 0, 43, 8, 44, 12, 37, 5, 40, 1, 0, 1, 1, 1, 2, 0, 0, 25, 38, 11, 24, 21, 66, 0, 2, 1, 5, 0, 0, 39, 72, 38, 4, 4, 4]\n",
      "54\n",
      "552\n",
      "[9, 3, 28, 3, 0, 0, 0, 0, 6, 37, 9, 11, 0, 0, 0, 0, 63, 5, 0, 0, 2, 38, 7, 13, 12, 11, 4, 24, 0, 0, 0, 0, 0, 0, 0, 0, 24, 30, 9, 20, 21, 53, 0, 0, 0, 0, 0, 0, 32, 60, 18, 0, 0, 0]\n",
      "error : \n",
      "total undercount metric 1:\t 0.5660194174757281\n",
      "total overcount metric 1:\t 0.37718446601941746\n",
      "total undercount metric 2:\t 0.5169902912621359\n",
      "total overcount metric 2:\t 0.32815533980582523\n",
      "total undercount metric 3:\t 0.45679611650485435\n",
      "total overcount metric 3:\t 0.26796116504854367\n",
      "==============================================================\n",
      "14329\n",
      "29468\n",
      "test accuarcy :  0.48625627799647075\n",
      "Step number for each segement\n",
      "[8, 10, 57, 7, 8, 10, 57, 7, 9, 80, 11, 6, 9, 80, 11, 6, 84, 22, 84, 22, 17, 82, 10, 80, 12, 63, 11, 57, 17, 82, 10, 80, 12, 63, 11, 57, 27, 46, 13, 31, 22, 82, 27, 46, 13, 31, 22, 82, 43, 82, 58, 43, 82, 58]\n",
      "[8, 10, 57, 8, 7, 7, 52, 2, 9, 85, 11, 7, 7, 73, 14, 5, 83, 22, 82, 21, 21, 82, 10, 73, 13, 64, 9, 58, 18, 78, 10, 79, 8, 60, 12, 59, 27, 46, 15, 30, 25, 82, 25, 47, 13, 31, 19, 67, 44, 81, 59, 36, 67, 59]\n",
      "54\n",
      "54\n",
      "210\n",
      "[0, 0, 1, 2, 1, 0, 3, 0, 0, 3, 1, 1, 2, 1, 3, 2, 0, 0, 37, 9, 2, 1, 2, 3, 1, 1, 0, 2, 3, 27, 2, 16, 1, 6, 1, 10, 0, 1, 2, 1, 1, 0, 2, 3, 2, 4, 2, 21, 7, 4, 2, 2, 10, 2]\n",
      "54\n",
      "30\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 3, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
      "error : \n",
      "total undercount metric 1:\t 0.14563106796116504\n",
      "total overcount metric 1:\t 0.11504854368932038\n",
      "total undercount metric 2:\t 0.2383495145631068\n",
      "total overcount metric 2:\t 0.20776699029126214\n",
      "total undercount metric 3:\t 0.04514563106796116\n",
      "total overcount metric 3:\t 0.014563106796116505\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "m1u, m1o, m2u, m2o, m3u, m3o = [], [], [], [], [], []\n",
    "    \n",
    "for k in range(len(test_logits_list)):\n",
    "    \n",
    "    test_logits = test_logits_list[k]   \n",
    "    \n",
    "    test_y_seq_list, test_logits_bin_list = [], []\n",
    "\n",
    "    for t in test_logits:  \n",
    "        t_all = [i for i in t[0]]\n",
    "        t_all.extend([i[-1] for i in t[1:]])\n",
    "    #     print(len(t_all)-len(t))\n",
    "\n",
    "        test_logits_part = [[round(i[0])] for i in t_all]\n",
    "        for i in range(1, len(test_logits_part)-1):\n",
    "            if(test_logits_part[i-1][0]!=test_logits_part[i][0] and test_logits_part[i-1][0]==test_logits_part[i+1][0]):\n",
    "                test_logits_part[i][0]=test_logits_part[i-1][0]  \n",
    "\n",
    "        test_logits_bin_list.append(test_logits_part)\n",
    "\n",
    "    for t in test_y:  \n",
    "        t_all = [i for i in t[0]]\n",
    "        t_all.extend([i[-1] for i in t[1:]])\n",
    "        test_y_seq_list.append(t_all)\n",
    "\n",
    "    # print(test_y_seq_list)\n",
    "\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for i in range(0, len(test_y_seq_list)):\n",
    "        total += len(test_y_seq_list[i])\n",
    "    #     print(len(test_y_seq_list[i]), len(test_logits_bin_list[i]))\n",
    "\n",
    "        for j in range(0, len(test_y_seq_list[i])):\n",
    "            if(test_y_seq_list[i][j][0] == test_logits_bin_list[i][j][0]):\n",
    "                count += 1\n",
    "\n",
    "    print(count)\n",
    "    print(total)\n",
    "    print(\"test accuarcy : \", count*1.0/total)\n",
    "    \n",
    "    #===========================================\n",
    "    step_time_actual, step_time_predict= [], []\n",
    "    step_time_actual_gap = []\n",
    "\n",
    "    #test_y_seq_list, test_logits_bin_list\n",
    "    for i in range(0, len(test_y_seq_list)):\n",
    "        step_time_actual_part, step_time_predict_part= [], []\n",
    "        for j in range(1, len(test_y_seq_list[i])):\n",
    "            if(abs(test_y_seq_list[i][j][0]-test_y_seq_list[i][j-1][0])>0.5):\n",
    "                step_time_actual_part.append(j)\n",
    "        #     if(abs(test_logits[i][0]-test_logits[i-1][0])>0.5):\n",
    "            if(abs(test_logits_bin_list[i][j][0]-test_logits_bin_list[i][j-1][0])>0.5):\n",
    "                step_time_predict_part.append(j)\n",
    "        step_time_actual.append(step_time_actual_part)\n",
    "        step_time_predict.append(step_time_predict_part)\n",
    "\n",
    "        step_time_actual_gap_part = []\n",
    "        step_time_actual_gap_part.append(0)\n",
    "    #     step_time_actual_gap_part.append(step_time_actual_part[0]/2.0)\n",
    "        for i in range(1, len(step_time_actual_part)):\n",
    "            step_time_actual_gap_part.append((step_time_actual_part[i-1]+step_time_actual_part[i])/2.0)\n",
    "        step_time_actual_gap_part.append(step_time_actual_part[-1]*2)\n",
    "        step_time_actual_gap.append(step_time_actual_gap_part)\n",
    "\n",
    "    print('Step number for each segement')\n",
    "    print([len(i) for i in step_time_actual])   \n",
    "    print([len(i) for i in step_time_predict])\n",
    "    \n",
    "    #===================================================\n",
    "    total_step_count = sum([len(i) for i in step_time_actual])\n",
    "    metric1_undercount = 0\n",
    "    metric2_undercount = 0\n",
    "    metric3_undercount = 0\n",
    "    metric1_overcount = 0\n",
    "    metric2_overcount = 0\n",
    "    metric3_overcount = 0\n",
    "    \n",
    "    metric1_overcount_list = []\n",
    "    metric2_overcount_list = []\n",
    "    metric3_overcount_list = []\n",
    "\n",
    "    print(len(test_y))\n",
    "\n",
    "    for i in range(len(test_y)):\n",
    "        step_count = len(step_time_actual[i])\n",
    "        undercount = 0\n",
    "        overcount = 0\n",
    "        \n",
    "        metric1_overcount += len([t for t in step_time_predict[i] if t<step_time_actual[i][0]])\n",
    "        for j in range(1, step_count):\n",
    "            gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][j-1] and t<step_time_actual[i][j]]\n",
    "        #     print(gap_count)\n",
    "            if(len(gap_count)>1):\n",
    "                overcount += len(gap_count)-1\n",
    "            if(len(gap_count)<1):\n",
    "                undercount += 1\n",
    "        gap_count = [t for t in step_time_predict[i] if t>=step_time_actual[i][-1]]\n",
    "        if(len(gap_count)>1):\n",
    "            overcount += len(gap_count)-1\n",
    "        if(len(gap_count)<1):\n",
    "            undercount += 1\n",
    "\n",
    "        metric1_undercount += undercount\n",
    "        metric1_overcount += overcount\n",
    "        metric1_overcount_list.append(overcount)\n",
    "\n",
    "        undercount = 0\n",
    "        overcount = 0\n",
    "        for j in range(1, len(step_time_actual_gap[i])):\n",
    "            gap_count = [t for t in step_time_predict[i] if t>=step_time_actual_gap[i][j-1] and t<step_time_actual_gap[i][j]]\n",
    "        #     print(gap_count)\n",
    "            if(len(gap_count)>1):\n",
    "                overcount += (len(gap_count)-1)\n",
    "            if(len(gap_count)<1):\n",
    "                undercount += 1    \n",
    "\n",
    "        metric2_undercount += undercount\n",
    "        metric2_overcount += overcount  \n",
    "        metric2_overcount_list.append(overcount)\n",
    "\n",
    "        diff = len(step_time_predict[i])-len(step_time_actual[i])\n",
    "#         print(step_time_actual[i])\n",
    "#         print(step_time_predict[i])\n",
    "#         print('------')\n",
    "\n",
    "        if(diff<0):\n",
    "    #         print('segement undercount : ', 1-len(step_time_predict[i])*1.0/len(step_time_actual[i]))\n",
    "            metric3_undercount -= diff\n",
    "            metric3_overcount_list.append(0)\n",
    "    #     if(diff>=0):\n",
    "        else:\n",
    "    #         print('segement overcount : ', 1-len(step_time_actual[i])*1.0/len(step_time_predict[i]))\n",
    "            metric3_overcount += diff\n",
    "            metric3_overcount_list.append(diff)\n",
    "\n",
    "    print(len(metric1_overcount_list))\n",
    "    print(sum(metric1_overcount_list))\n",
    "    print(metric1_overcount_list)\n",
    "    print(len(metric3_overcount_list))\n",
    "    print(sum(metric3_overcount_list))\n",
    "    print(metric3_overcount_list)\n",
    "\n",
    "    print('error : ')\n",
    "    print(\"total undercount metric 1:\\t\", metric1_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 1:\\t\", metric1_overcount*1.0/total_step_count)\n",
    "    print(\"total undercount metric 2:\\t\", metric2_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 2:\\t\", metric2_overcount*1.0/total_step_count)\n",
    "    print(\"total undercount metric 3:\\t\", metric3_undercount*1.0/total_step_count)\n",
    "    print(\"total overcount metric 3:\\t\", metric3_overcount*1.0/total_step_count)\n",
    "    \n",
    "    m1u.append(metric1_undercount*1.0/total_step_count)\n",
    "    m1o.append(metric1_overcount*1.0/total_step_count)\n",
    "    m2u.append(metric2_undercount*1.0/total_step_count)\n",
    "    m2o.append(metric2_overcount*1.0/total_step_count)\n",
    "    m3u.append(metric3_undercount*1.0/total_step_count)\n",
    "    m3o.append(metric3_overcount*1.0/total_step_count)\n",
    "    \n",
    "    print(\"==============================================================\")\n",
    "\n",
    "# filename = 'tmp/na_test_timesteps='+str(timesteps)+'_trainingsteps='+str(training_steps)+'lr='+str(0.1)+'1.csv'\n",
    "# with open(filename,\"w\") as csvfile: \n",
    "#     writer = csv.writer(csvfile)\n",
    "#     writer.writerow([\"cv0\",\"cv1\",\"cv2\",\"cv3\"])\n",
    "#     writer.writerows([m1u, m1o, m2u, m2o, m3u, m3o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
